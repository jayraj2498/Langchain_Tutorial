{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vector store take cares of of storing embedded data and perform vector serch for you "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benefits of Using Chroma DB\n",
    "\n",
    "Scalability: Capable of handling large volumes of vector data.\n",
    "\n",
    "Efficiency: Optimized for fast indexing and querying of vectors.\n",
    "\n",
    "Integration: Seamlessly integrates with LangChain, making it easier to build advanced NLP applications. \n",
    "\n",
    "Like Chrmadb we have :- FAISS & LANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config \n",
    "secrete_key = config('OPENAI_API_KEY') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings  \n",
    "models=OpenAIEmbeddings (openai_api_key=secrete_key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader    # to load text \n",
    "from langchain.text_splitter import CharacterTextSplitter       # to split text \n",
    "from langchain_community.vectorstores import Chroma   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load document \n",
    "\n",
    "loader =TextLoader('E:\\\\Langchain_Prac\\\\8.vector_store_Chromadb\\\\history.txt') \n",
    "history_doc=loader.load() \n",
    "\n",
    "# split_document \n",
    "\n",
    "text_spliter =CharacterTextSplitter(chunk_size=500 , chunk_overlap=0) \n",
    "history_document =text_spliter.split_documents(history_doc)  \n",
    "\n",
    "\n",
    "# embedded_model \n",
    "\n",
    "em_model=OpenAIEmbeddings (openai_api_key=secrete_key) \n",
    "\n",
    "\n",
    "#store \n",
    "\n",
    "db=Chroma.from_documents(history_document,em_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='The Birth of AI:\\nThe field of AI was officially founded in 1956 at the Dartmouth Conference, where key figures like John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon convened to discuss the potential of \"thinking machines.\" This event is often considered the birth of AI as a discipline.', metadata={'source': 'E:\\\\Langchain_Prac\\\\8.vector_store_Chromadb\\\\history.txt'}), Document(page_content=\"The Rise of Machine Learning:\\nAI experienced a resurgence in the 1990s and 2000s with the advent of machine learning, a subset of AI focused on algorithms that learn from data. Breakthroughs in neural networks, particularly deep learning, enabled significant advancements in image and speech recognition. In 1997, IBM's Deep Blue made history by defeating world chess champion Garry Kasparov.\", metadata={'source': 'E:\\\\Langchain_Prac\\\\8.vector_store_Chromadb\\\\history.txt'}), Document(page_content=\"Early Beginnings:\\nThe concept of AI can be traced back to ancient myths and philosophical discussions about artificial beings with intelligence. However, the formal foundation of AI was laid in the mid-20th century. In 1950, Alan Turing introduced the Turing Test to evaluate a machine's ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.\", metadata={'source': 'E:\\\\Langchain_Prac\\\\8.vector_store_Chromadb\\\\history.txt'}), Document(page_content='Early Milestones:\\nThe initial decades saw the development of fundamental AI programs and algorithms. In 1956, Allen Newell and Herbert A. Simon created the Logic Theorist, considered one of the first AI programs. In 1966, Joseph Weizenbaum developed ELIZA, a program that could simulate a conversation with a human.', metadata={'source': 'E:\\\\Langchain_Prac\\\\8.vector_store_Chromadb\\\\history.txt'})]\n"
     ]
    }
   ],
   "source": [
    "# queries  \n",
    "\n",
    "query = \"the birth of AI \"      # it serch that topic in .txt file and that realated content will get as your op \n",
    "\n",
    "similar_doc =db.similarity_search(query) \n",
    "\n",
    "print(similar_doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Birth of AI:\n",
      "The field of AI was officially founded in 1956 at the Dartmouth Conference, where key figures like John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon convened to discuss the potential of \"thinking machines.\" This event is often considered the birth of AI as a discipline.\n"
     ]
    }
   ],
   "source": [
    "print(similar_doc[0].page_content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Birth of AI:\n",
      "The field of AI was officially founded in 1956 at the Dartmouth Conference, where key figures like John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon convened to discuss the potential of \"thinking machines.\" This event is often considered the birth of AI as a discipline.\n"
     ]
    }
   ],
   "source": [
    "## we can use vector store retraval  , it work similar as abouve \n",
    "\n",
    "retriver =db.as_retriever() \n",
    "\n",
    "similar_docs =retriver.get_relevant_documents(query) \n",
    "\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Birth of AI:\n",
      "The field of AI was officially founded in 1956 at the Dartmouth Conference, where key figures like John McCarthy, Marvin Minsky, Nathaniel Rochester, and Claude Shannon convened to discuss the potential of \"thinking machines.\" This event is often considered the birth of AI as a discipline.\n"
     ]
    }
   ],
   "source": [
    "retriver =db.as_retriever() \n",
    "\n",
    "similar_docs =retriver.invoke(query) \n",
    "\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if we want to store these in our system or cloud then we can store it by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Load document \n",
    "\n",
    "loader =TextLoader('E:\\\\Langchain_Prac\\\\8.vector_store_Chromadb\\\\history.txt') \n",
    "history_doc=loader.load() \n",
    "\n",
    "# split_document \n",
    "\n",
    "text_spliter =CharacterTextSplitter(chunk_size=500 , chunk_overlap=0) \n",
    "history_document =text_spliter.split_documents(history_doc)  \n",
    "\n",
    "\n",
    "# embedded_model \n",
    "\n",
    "em_model=OpenAIEmbeddings (openai_api_key=secrete_key) \n",
    "\n",
    "\n",
    "#store \n",
    "\n",
    "db=Chroma.from_documents(history_document,em_model , persist_directory=\"./chroma_db_dir\")   # here you have to add dir name \n",
    "\n",
    "db.persist()      # <--- you will get directory and evrything will get store in that \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Future of AI:\n",
      "The future of AI holds tremendous potential. Ongoing research aims to achieve general AI, systems that possess the ability to understand, learn, and apply intelligence across a broad range of tasks, similar to human capabilities. The integration of AI with other emerging technologies like quantum computing and biotechnology could further revolutionize how we live and work.\n"
     ]
    }
   ],
   "source": [
    "# now what is document we store from that dirctory we will read it from chromadb \n",
    "\n",
    "db_connections =Chroma(embedding_function=em_model , persist_directory=\"./chroma_db_dir\")   \n",
    "\n",
    "query= \" The Future of AI ?\" \n",
    "\n",
    "retriver =db_connections.as_retriever() \n",
    "\n",
    "similar_docs =retriver.invoke(query) \n",
    "\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Future of AI:\n",
      "The future of AI holds tremendous potential. Ongoing research aims to achieve general AI, systems that possess the ability to understand, learn, and apply intelligence across a broad range of tasks, similar to human capabilities. The integration of AI with other emerging technologies like quantum computing and biotechnology could further revolutionize how we live and work.\n"
     ]
    }
   ],
   "source": [
    "## by using search_kwargs \n",
    "\n",
    "retriver =db_connections.as_retriever(search_kwargs={\"k\":1})   # it holds the small output  \n",
    "\n",
    "similar_docs =retriver.invoke(query) \n",
    "\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if you want to add new file inthe exiating file then you can add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load document \n",
    "\n",
    "loader =TextLoader('E:\\\\Langchain_Prac\\\\8.vector_store_Chromadb\\\\quantum_computing_basics.txt') \n",
    "science_doc=loader.load() \n",
    "\n",
    "# split_document \n",
    "\n",
    "text_spliter =CharacterTextSplitter(chunk_size=500 , chunk_overlap=0) \n",
    "science_document =text_spliter.split_documents(science_doc)  \n",
    "\n",
    "\n",
    "# embedded_model \n",
    "\n",
    "em_model=OpenAIEmbeddings (openai_api_key=secrete_key) \n",
    "\n",
    "\n",
    "#store \n",
    "\n",
    "db=Chroma.from_documents(science_document ,em_model , persist_directory=\"./chroma_db_dir\")   # we will keep same query  \n",
    "\n",
    "db.persist()     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Future of AI:\n",
      "The future of AI holds tremendous potential. Ongoing research aims to achieve general AI, systems that possess the ability to understand, learn, and apply intelligence across a broad range of tasks, similar to human capabilities. The integration of AI with other emerging technologies like quantum computing and biotechnology could further revolutionize how we live and work.\n"
     ]
    }
   ],
   "source": [
    "#  here you can add same question , cause our data is get merege \n",
    "\n",
    "# now what is document we store from that dirctory we will read it from chromadb \n",
    "\n",
    "db_connections =Chroma(embedding_function=em_model , persist_directory=\"./chroma_db_dir\")   \n",
    "\n",
    "query= \" The Future of AI ?\" \n",
    "\n",
    "retriver =db_connections.as_retriever() \n",
    "\n",
    "similar_docs =retriver.invoke(query) \n",
    "\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenges:\n",
      "Despite its potential, quantum computing faces several challenges. Maintaining qubits in a stable state (coherence) and error correction are significant hurdles. Qubits are highly susceptible to environmental disturbances, leading to decoherence. Researchers are actively working on developing error-correcting codes and more stable qubit implementations.\n"
     ]
    }
   ],
   "source": [
    "db_connections =Chroma(embedding_function=em_model , persist_directory=\"./chroma_db_dir\")   \n",
    "\n",
    "query= \" quantum_computing Challenges?\"    # see here \n",
    "\n",
    "retriver =db_connections.as_retriever() \n",
    "\n",
    "similar_docs =retriver.invoke(query) \n",
    "\n",
    "print(similar_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings  # Example for embeddings, use the appropriate one for your model\n",
    "\n",
    "# Initialize the embedding model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Initialize Chroma DB as the vector store\n",
    "vector_store = Chroma(embedding_function=embeddings.embed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"This is a sample text\", \"Another example text\"]\n",
    "ids = [\"text1\", \"text2\"]  # Unique identifiers for the texts\n",
    "\n",
    "# Embed the texts and add them to the vector store\n",
    "vector_store.add_texts(texts, ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Sample query text\"\n",
    "query_embedding = embeddings.embed_text(query_text)\n",
    "\n",
    "# Perform a similarity search in the vector store\n",
    "results = vector_store.similarity_search(query_embedding)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Found text: {result['text']} with similarity score: {result['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings  # Use appropriate embeddings model\n",
    "\n",
    "# Initialize the embedding model\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Initialize Chroma DB as the vector store\n",
    "vector_store = Chroma(embedding_function=embeddings.embed_text)\n",
    "\n",
    "# Sample texts\n",
    "texts = [\"This is a sample text\", \"Another example text\"]\n",
    "ids = [\"text1\", \"text2\"]  # Unique identifiers for the texts\n",
    "\n",
    "# Embed the texts and add them to the vector store\n",
    "vector_store.add_texts(texts, ids)\n",
    "\n",
    "# Query example\n",
    "query_text = \"Sample query text\"\n",
    "query_embedding = embeddings.embed_text(query_text)\n",
    "\n",
    "# Perform a similarity search in the vector store\n",
    "results = vector_store.similarity_search(query_embedding)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Found text: {result['text']} with similarity score: {result['score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content has been saved to quantum_computing_basics.txt\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\"The Basics of Quantum Computing\n",
    "\n",
    "Quantum computing is a rapidly advancing field that leverages the principles of quantum mechanics to perform computations. Unlike classical computers, which use bits as the smallest unit of data (represented as 0 or 1), quantum computers use quantum bits or qubits. Qubits can represent and store data in a more complex manner due to the phenomena of superposition and entanglement.\n",
    "\n",
    "Superposition:\n",
    "Superposition allows a qubit to be in a state of 0, 1, or both simultaneously. This property enables quantum computers to process a vast amount of possibilities at once, significantly increasing their computational power for certain tasks compared to classical computers.\n",
    "\n",
    "Entanglement:\n",
    "Entanglement is a phenomenon where two or more qubits become interconnected such that the state of one qubit directly influences the state of another, regardless of the distance between them. This interconnectedness allows quantum computers to perform complex operations more efficiently.\n",
    "\n",
    "Quantum Gates and Circuits:\n",
    "Quantum computers use quantum gates to manipulate qubits. These gates perform operations on qubits, similar to logic gates in classical computing, but with the ability to handle superposition and entanglement. Quantum circuits are networks of quantum gates, designed to carry out specific computations.\n",
    "\n",
    "Applications:\n",
    "Quantum computing holds promise for revolutionizing various fields, including cryptography, drug discovery, optimization problems, and artificial intelligence. For instance, quantum algorithms like Shor's algorithm can potentially break widely-used encryption methods, while quantum simulations can model molecular interactions for drug development more accurately.\n",
    "\n",
    "Challenges:\n",
    "Despite its potential, quantum computing faces several challenges. Maintaining qubits in a stable state (coherence) and error correction are significant hurdles. Qubits are highly susceptible to environmental disturbances, leading to decoherence. Researchers are actively working on developing error-correcting codes and more stable qubit implementations.\n",
    "\n",
    "Future Outlook:\n",
    "The future of quantum computing is promising, with ongoing advancements in quantum hardware and algorithms. Companies like IBM, Google, and Microsoft, as well as numerous startups, are making significant strides in bringing practical quantum computers closer to reality. As the technology matures, we can expect quantum computing to unlock new possibilities and transform industries.\n",
    "\"\"\"\n",
    "\n",
    "# Save the content to a .txt file\n",
    "with open(\"quantum_computing_basics.txt\", \"w\") as file:\n",
    "    file.write(content)\n",
    "\n",
    "print(\"Content has been saved to quantum_computing_basics.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
