{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chains \n",
    "\n",
    "means you can use the sequence of call in you application  , like one after another and at the end you get response \n",
    "\n",
    "your first call output can be use as for the sencond call of input  \n",
    "\n",
    "Chains in LangChain are sequences of operations or calls to language models (LLMs) that can be executed in order. These operations can include text generation, data processing, API calls, and more. Chains allow you to break down complex tasks into smaller, manageable steps and handle them sequentially or conditionally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config \n",
    "secrete_key = config('OPENAI_API_KEY')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  \n",
    "chat =ChatOpenAI(openai_api_key=secrete_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate ,ChatPromptTemplate, ChatMessagePromptTemplate \n",
    "from langchain_core.output_parsers import StrOutputParser  \n",
    "from langchain.chains import LLMChain   \n",
    "from operator import itemgetter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'Rolls Royals', 'text': \"Rolls-Royce is a British luxury automobile maker founded in 1904 by Charles Rolls and Henry Royce. The company is known for producing high-end, handcrafted vehicles that are often customized to the buyer's specifications. Rolls-Royce cars are renowned for their impeccable quality, attention to detail, and prestigious reputation in the automotive industry.\"}\n"
     ]
    }
   ],
   "source": [
    "# example 1  chain \n",
    "\n",
    "human_template = \"tell me a fact about {topic}\"  \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages( [HumanMessagePromptTemplate.from_template(human_template)]) \n",
    "\n",
    "chain =LLMChain(llm=chat , prompt=chat_prompt) \n",
    "\n",
    "response = chain.invoke(input=\"Rolls Royals\") \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'javasript', 'text': 'JavaScript was created by Brendan Eich in just 10 days in 1995 while he was working at Netscape Communications Corporation.'}\n"
     ]
    }
   ],
   "source": [
    "# anothe way \n",
    "\n",
    "response = chain.invoke({\"topic\":\"javasript\"}) \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='One interesting fact about NASA is that the organization was established on July 29, 1958, by the National Aeronautics and Space Act signed by President Dwight D. Eisenhower.' response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 14, 'total_tokens': 52}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-e797f10c-f344-4e80-ac25-9d7b82d295ff-0'\n"
     ]
    }
   ],
   "source": [
    "# new method \n",
    "\n",
    "chains= chat_prompt | chat \n",
    "\n",
    "response=chains.invoke({\"topic\":\"nasa\"}) \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India is home to more than 2,000 distinct ethnic groups and over 1,600 spoken languages.\n"
     ]
    }
   ],
   "source": [
    "human_template = \"tell me a unique thing about {topic} in one line \"  \n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages( [HumanMessagePromptTemplate.from_template(human_template)])   \n",
    "\n",
    "chain = chat_prompt| chat | StrOutputParser() \n",
    "\n",
    "response = chain.invoke({\"topic\":\"india\"})  \n",
    "\n",
    "print(response) \n",
    "\n",
    "\n",
    "# StrOutputParser()   these will put direct answer only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "रोहित शर्मा का शहर नागपुर, महाराष्ट्र, भारत में है। इस शहर के बारे में प्रसिद्ध यह है कि यह भारत में ऑरेंज सिटी के नाम से भी जाना जाता है क्योंकि यह भारत में अग्रवाल ऑरेंज का मुख्य उत्पादन केंद्र है।\n"
     ]
    }
   ],
   "source": [
    "# ex2  Multiple chain  \n",
    "\n",
    "\n",
    "chat_prompt1 = ChatPromptTemplate.from_template(\"what is the city {person} is from ?\")\n",
    "\n",
    "chat_prompt2 = ChatPromptTemplate.from_template(\"\"\"what country is the city {city} in and \n",
    "what is the famous abt that city ? respond in {language}\"\"\")  \n",
    "\n",
    "city_chain = chat_prompt1 | chat | StrOutputParser() \n",
    "\n",
    "country_chain= ( {\"city\" : city_chain ,\"language\":itemgetter(\"language\")} | chat_prompt2 |chat | StrOutputParser() ) \n",
    "\n",
    "response = country_chain.invoke( {\"person\":\"rohit sharma\"  , \"language\":\"Hindi\"}) \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vadnagar is a town in the Mehsana district of Gujarat, India. It is famous for being the birthplace of Narendra Modi, the current Prime Minister of India. Narendra Modi was born in Vadnagar in 1950 and spent his childhood there. The city is also known for its historical and cultural significance, with ancient temples and monuments dating back centuries.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate ,ChatPromptTemplate, ChatMessagePromptTemplate \n",
    "from langchain_core.output_parsers import StrOutputParser  \n",
    "from langchain.chains import LLMChain   \n",
    "from operator import itemgetter \n",
    "\n",
    "chat_prompt1 = ChatPromptTemplate.from_template(\"what is the city {person} is from ?\")\n",
    "\n",
    "chat_prompt2 = ChatPromptTemplate.from_template(\"\"\"what country is the city {city} in and \n",
    "what is the famous abt that city ? respond in {language}\"\"\")  \n",
    "\n",
    "person_chain = chat_prompt1 | chat | StrOutputParser() \n",
    "\n",
    "country_chain= ( {\"city\" : person_chain ,\"language\":itemgetter(\"language\")} | chat_prompt2 |chat | StrOutputParser() ) \n",
    "\n",
    "response = country_chain.invoke( {\"person\":\"Narendra modi\"  , \"language\":\"English\"}) \n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat =ChatOpenAI(openai_api_key=secrete_key) \n",
    "from langchain.prompts import HumanMessagePromptTemplate ,ChatPromptTemplate, ChatMessagePromptTemplate \n",
    "from langchain_core.output_parsers import StrOutputParser  \n",
    "from langchain.chains import LLMChain   \n",
    "from operator import itemgetter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain_core.output_parsers import StrOutputParser  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "/# from langchain.prompts import ChatPromptTemplate\n",
    "# # from langchain.llms import OpenAI\n",
    "# from langchain.chains import SequentialChain\n",
    "# from langchain_core.output_parsers import StrOutputParser  \n",
    "\n",
    "# # Define your API key for OpenAI\n",
    "# openai_api_key = secrete_key\n",
    "\n",
    "# # Initialize the language model\n",
    "# llm = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Define chat prompts\n",
    "story_prompt = ChatPromptTemplate.from_template(\"Write a short story based on the title: '{title}'.\")\n",
    "summary_prompt = ChatPromptTemplate.from_template(\"Summarize the following story: '{story}'.\")\n",
    "translation_prompt = ChatPromptTemplate.from_template(\"Translate the following summary into {language}: '{summary}'.\")\n",
    "\n",
    "# Define output parsers\n",
    "str_output_parser = StrOutputParser()\n",
    "\n",
    "# Define the chains\n",
    "story_chain = SequentialChain(\n",
    "    prompt_template=story_prompt,\n",
    "    llm=chat,\n",
    "    output_parser=str_output_parser\n",
    ")\n",
    "\n",
    "summary_chain = SequentialChain(\n",
    "    prompt_template=summary_prompt,\n",
    "    llm=chat,\n",
    "    output_parser=str_output_parser\n",
    ")\n",
    "\n",
    "translation_chain = SequentialChain(\n",
    "    prompt_template=translation_prompt,\n",
    "    llm=chat,\n",
    "    output_parser=str_output_parser\n",
    ")\n",
    "\n",
    "def create_and_translate_story(inputs):\n",
    "    # Generate the story\n",
    "    story_response = story_chain.run({\"title\": inputs[\"title\"]})\n",
    "    story = story_response['output']\n",
    "    \n",
    "    # Summarize the story\n",
    "    summary_response = summary_chain.run({\"story\": story})\n",
    "    summary = summary_response['output']\n",
    "    \n",
    "    # Translate the summary\n",
    "    translation_response = translation_chain.run({\"summary\": summary, \"language\": inputs[\"language\"]})\n",
    "    translation = translation_response['output']\n",
    "    \n",
    "    return {\n",
    "        \"story\": story,\n",
    "        \"summary\": summary,\n",
    "        \"translation\": translation\n",
    "    }\n",
    "\n",
    "# Invoke the chain with inputs\n",
    "response = create_and_translate_story({\"title\": \"The Adventures of a Brave Mouse\", \"language\": \"english\"})\n",
    "\n",
    "# Print the response\n",
    "print(\"Generated Story:\\n\", response[\"story\"])\n",
    "print(\"\\nSummary:\\n\", response[\"summary\"])\n",
    "print(\"\\nTranslated Summary:\\n\", response[\"translation\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Customer Support Chatbot\n",
    "In this scenario, we'll create a chain that helps a customer support chatbot handle queries by fetching relevant information from a knowledge base and generating a response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To reset your password, go to the login page and click on the \"Forgot password\" link. Enter your email or username, check your email for instructions, create a new password, and log in. If you need further help, contact customer support.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "# from langchain.llms import OpenAI\n",
    "# from langchain.chains import SequentialChain\n",
    "from langchain_core.output_parsers import StrOutputParser \n",
    "\n",
    "\n",
    "\n",
    "# Define chat prompts\n",
    "query_prompt = ChatPromptTemplate.from_template(\"\"\"Customer asked: '{query}'. Provide a detailed answer\n",
    " based on the knowledge base.\"\"\")\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(\"Summarize the following answer for clarity: '{answer}'.\")\n",
    "\n",
    "# Define output parsers\n",
    "str_output_parser = StrOutputParser()\n",
    "\n",
    "query_chain  = query_prompt | chat | str_output_parser \n",
    "\n",
    "\n",
    "summary_chain = ( {\"answer\" : query_chain } | summary_prompt | chat | str_output_parser ) \n",
    " \n",
    "\n",
    "response = summary_chain.invoke( {\"query\": \"How can I reset my password?\"}) \n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Content Creation for Social Media\n",
    "In this scenario, we'll create a chain that generates a blog post based on a given topic and then creates social media posts to promote the blog.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.output_parsers import StrOutputParser\n",
    "\n",
    "# Define your API key for OpenAI\n",
    "openai_api_key = 'your_openai_api_key_here'\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Define chat prompts\n",
    "blog_prompt = ChatPromptTemplate.from_template(\"Write a detailed blog post on the topic: '{topic}'.\")\n",
    "social_media_prompt = ChatPromptTemplate.from_template(\"Create three social media posts to promote the following blog post: '{blog_post}'.\")\n",
    "\n",
    "# Define output parsers\n",
    "str_output_parser = StrOutputParser()\n",
    "\n",
    "# Define the chains\n",
    "blog_chain = SequentialChain(\n",
    "    prompt_template=blog_prompt,\n",
    "    llm=llm,\n",
    "    output_parser=str_output_parser\n",
    ")\n",
    "\n",
    "social_media_chain = SequentialChain(\n",
    "    prompt_template=social_media_prompt,\n",
    "    llm=llm,\n",
    "    output_parser=str_output_parser\n",
    ")\n",
    "\n",
    "def content_creation(inputs):\n",
    "    # Generate the blog post\n",
    "    blog_response = blog_chain.run({\"topic\": inputs[\"topic\"]})\n",
    "    blog_post = blog_response['output']\n",
    "    \n",
    "    # Generate social media posts to promote the blog\n",
    "    social_media_response = social_media_chain.run({\"blog_post\": blog_post})\n",
    "    social_media_posts = social_media_response['output']\n",
    "    \n",
    "    return {\n",
    "        \"blog_post\": blog_post,\n",
    "        \"social_media_posts\": social_media_posts\n",
    "    }\n",
    "\n",
    "# Invoke the chain with inputs\n",
    "response = content_creation({\"topic\": \"The Benefits of Meditation\"})\n",
    "\n",
    "# Print the response\n",
    "print(\"Blog Post:\\n\", response[\"blog_post\"])\n",
    "print(\"\\nSocial Media Posts:\\n\", response[\"social_media_posts\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Automated Research Assistant\n",
    "In this scenario, we'll create a chain that helps an automated research assistant gather information on a given topic, summarize the information, and provide key insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.output_parsers import StrOutputParser\n",
    "\n",
    "# Define your API key for OpenAI\n",
    "openai_api_key = 'your_openai_api_key_here'\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Define chat prompts\n",
    "research_prompt = ChatPromptTemplate.from_template(\"Gather detailed information on the topic: '{topic}'.\")\n",
    "summary_prompt = ChatPromptTemplate.from_template(\"Summarize the following information: '{information}'.\")\n",
    "insight_prompt = ChatPromptTemplate.from_template(\"Provide key insights based on the summary: '{summary}'.\")\n",
    "\n",
    "# Define output parsers\n",
    "str_output_parser = StrOutputParser()\n",
    "\n",
    "# Define the chains\n",
    "research_chain = SequentialChain(\n",
    "    prompt_template=research_prompt,\n",
    "    llm=llm,\n",
    "    output_parser=str_output_parser\n",
    ")\n",
    "\n",
    "summary_chain = SequentialChain(\n",
    "    prompt_template=summary_prompt,\n",
    "    llm=llm,\n",
    "    output_parser=str_output_parser\n",
    ")\n",
    "\n",
    "insight_chain = SequentialChain(\n",
    "    prompt_template=insight_prompt,\n",
    "    llm=llm,\n",
    "    output_parser=str_output_parser\n",
    ")\n",
    "\n",
    "def research_assistant(inputs):\n",
    "    # Gather detailed information\n",
    "    research_response = research_chain.run({\"topic\": inputs[\"topic\"]})\n",
    "    information = research_response['output']\n",
    "    \n",
    "    # Summarize the information\n",
    "    summary_response = summary_chain.run({\"information\": information})\n",
    "    summary = summary_response['output']\n",
    "    \n",
    "    # Provide key insights\n",
    "    insight_response = insight_chain.run({\"summary\": summary})\n",
    "    insights = insight_response['output']\n",
    "    \n",
    "    return {\n",
    "        \"information\": information,\n",
    "        \"summary\": summary,\n",
    "        \"insights\": insights\n",
    "    }\n",
    "\n",
    "# Invoke the chain with inputs\n",
    "response = research_assistant({\"topic\": \"Recent Advances in Artificial Intelligence\"})\n",
    "\n",
    "# Print the response\n",
    "print(\"Detailed Information:\\n\", response[\"information\"])\n",
    "print(\"\\nSummary:\\n\", response[\"summary\"])\n",
    "print(\"\\nKey Insights:\\n\", response[\"insights\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import TransformChain, SimpleSequentialChain\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import TransformChain, SimpleSequentialChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Define your API key for OpenAI\n",
    "# openai_api_key = 'your_openai_api_key_here'\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(api_key=secrete_key)\n",
    "\n",
    "# Define chat prompts\n",
    "research_prompt = ChatPromptTemplate.from_template(\"Gather detailed information on the topic: '{topic}'.\")\n",
    "summary_prompt = ChatPromptTemplate.from_template(\"Summarize the following information: '{information}'.\")\n",
    "insight_prompt = ChatPromptTemplate.from_template(\"Provide key insights based on the summary: '{summary}'.\")\n",
    "\n",
    "# Define the chains\n",
    "research_chain = TransformChain(prompt=research_prompt, llm=llm, output_parser=StrOutputParser())\n",
    "summary_chain = TransformChain(prompt=summary_prompt, llm=llm, output_parser=StrOutputParser())\n",
    "insight_chain = TransformChain(prompt=insight_prompt, llm=llm, output_parser=StrOutputParser())\n",
    "\n",
    "# Combine chains\n",
    "combined_chain = SimpleSequentialChain(chains=[research_chain, summary_chain, insight_chain])\n",
    "\n",
    "# Function to handle research\n",
    "def research_assistant(inputs):\n",
    "    response = combined_chain.run({\"topic\": inputs[\"topic\"]})\n",
    "    information = response['information']\n",
    "    summary = response['summary']\n",
    "    insights = response['insights']\n",
    "    return {\n",
    "        \"information\": information,\n",
    "        \"summary\": summary,\n",
    "        \"insights\": insights\n",
    "    }\n",
    "\n",
    "# Invoke the chain with inputs\n",
    "response = research_assistant({\"topic\": \"Recent Advances in Artificial Intelligence\"})\n",
    "\n",
    "# Print the response\n",
    "print(\"Detailed Information:\\n\", response[\"information\"])\n",
    "print(\"\\nSummary:\\n\", response[\"summary\"])\n",
    "print(\"\\nKey Insights:\\n\", response[\"insights\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Load documents\n",
    "loader = TextLoader(\"E:\\\\Langchain_Prac\\\\9.contextual_retrival\\\\context.ipynb\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Create vector store\n",
    "vector_store = Chroma.from_documents(documents)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Create question answering chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "# Ask a question\n",
    "query = \"What is the future od criecket ?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Define your API key for OpenAI\n",
    "openai_api_key = 'your_openai_api_key_here'\n",
    "\n",
    "# Initialize the language model\n",
    "llm = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "# Define a prompt template\n",
    "prompt_template = PromptTemplate(template=\"You are a helpful assistant. Answer the following question: {question}\")\n",
    "\n",
    "# Create a simple chain that uses the prompt template and LLM\n",
    "simple_chain = SimpleChain(prompt_template=prompt_template, llm=llm)\n",
    "\n",
    "# User input\n",
    "user_input = \"What is the capital of France?\"\n",
    "\n",
    "# Generate the response using the chain\n",
    "response = simple_chain.run({\"question\": user_input})\n",
    "\n",
    "# Print the response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'A time-traveling scientist discovers a parallel universe', 'text': \"Dr. Olivia Smith, a brilliant time-traveling scientist, had always dreamed of discovering new dimensions. One day, while experimenting with her latest invention, she accidentally opened a portal to a parallel universe.\\n\\nStepping through, Olivia was amazed by the sight before her. The sky was a deep shade of purple, and the trees seemed to glow with an ethereal light. Curious, she began exploring this strange world, documenting her findings along the way.\\n\\nAs she delved deeper into the parallel universe, Olivia encountered beings unlike any she had ever seen before. They communicated through telepathy and moved with an otherworldly grace. Fascinated, Olivia tried to learn their ways and understand their culture.\\n\\nBut just as she was beginning to feel at home in this new world, Olivia's time-travel device malfunctioned, threatening to strand her in the parallel universe forever. With quick thinking and a stroke of luck, she managed to repair the device and return to her own reality, forever changed by her incredible journey.\"}\n"
     ]
    }
   ],
   "source": [
    "# Text Generation Chain:\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "chat =ChatOpenAI(openai_api_key=secrete_key)\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are a creative writer. Your task is to write a short story in minimum lines  based on the following prompt:\n",
    "\n",
    "Prompt: {prompt}\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt object\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"prompt\"])\n",
    "\n",
    "# Create the chain\n",
    "llm = OpenAI(temperature=0.9)\n",
    "chain = LLMChain(llm=chat , prompt=prompt)\n",
    "\n",
    "# Generate text\n",
    "story_prompt = \"A time-traveling scientist discovers a parallel universe\"\n",
    "story = chain.invoke(story_prompt)\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SummarizationChain' from 'langchain.chains' (c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain\\chains\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummarizationChain\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextLoader\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SummarizationChain' from 'langchain.chains' (c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain\\chains\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import SummarizationChain\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarization Chain:\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "# from langchain.chains import SummarizationChain\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Load documents\n",
    "loader = TextLoader(\"E:\\\\Langchain_Prac\\\\9.contextual_retrival\\\\notes.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Create summarization chain\n",
    "llm = OpenAI()\n",
    "summarization_chain =  StuffDocumentsChain(llm=chat)\n",
    "\n",
    "# Summarize documents\n",
    "summaries = summarization_chain.run(documents)\n",
    "print(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation Chain:\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import TranslationChain\n",
    "\n",
    "# Create translation chain\n",
    "translation_chain = TranslationChain(task=\"translation\", model=OpenAI())\n",
    "\n",
    "\n",
    "# Translate text\n",
    "text_to_translate = \"Hello, how are you?\"\n",
    "translated_text = translation_chain.run(text_to_translate, target_language=\"fr\")\n",
    "print(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Chain:\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the prompt template\n",
    "prompt_template = \"\"\"\n",
    "You are an AI assistant tasked with planning a trip.\n",
    "\n",
    "Here are the details:\n",
    "{trip_details}\n",
    "\n",
    "Based on the provided details, please create an itinerary for the trip, including the following:\n",
    "- Flight details (departure, arrival, and any layovers)\n",
    "- Hotel accommodations\n",
    "- Activities or attractions to visit\n",
    "\n",
    "Your itinerary should be well-organized and easy to follow.\n",
    "\"\"\"\n",
    "\n",
    "# Create the prompt object\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"trip_details\"])\n",
    "\n",
    "# Create the chain\n",
    "# llm = OpenAI(temperature=0.7)\n",
    "chain = LLMChain(llm=chat, prompt=prompt)\n",
    "\n",
    "# Plan a trip\n",
    "trip_details = \"A family of 4 wants to visit Paris for 5 nights. Departure from New York on June 1st.\"\n",
    "itinerary = chain.run(trip_details)\n",
    "print(itinerary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation Chain:\n",
    "\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Create conversation chain\n",
    "memory = ConversationBufferMemory()\n",
    "llm = OpenAI()\n",
    "conversation = ConversationChain(llm=llm, memory=memory)\n",
    "\n",
    "# Start a conversation\n",
    "print(\"AI: Hello! How can I assist you today?\")\n",
    "while True:\n",
    "    user_input = input(\"Human: \")\n",
    "    response = conversation.predict(input=user_input)\n",
    "    print(f\"AI: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import ChromaRetriever\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# Load the documents into a Chroma vector store\n",
    "documents = [\n",
    "    \"The Lord of the Rings is a book series written by J.R.R. Tolkien.\",\n",
    "    \"The Hobbit is a fantasy novel written by J.R.R. Tolkien.\",\n",
    "    \"Harry Potter is a book series written by J.K. Rowling.\"\n",
    "]\n",
    "vectorstore = Chroma.from_texts(documents)\n",
    "\n",
    "# Create a retriever and a question-answering chain\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa = RetrievalQA.from_chain_type(llm=chat, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "\n",
    "# Ask a question\n",
    "query = \"Who wrote The Lord of the Rings books?\"\n",
    "result = qa({\"query\": query})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
