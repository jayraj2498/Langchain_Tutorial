{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchian putput parser tell us that , the response you get how you format that msg \n",
    "- here you have diff diff output parser classe provided by openai \n",
    "- extract specific information from our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain_core\\utils\\utils.py:161: UserWarning: WARNING! open_api_key is not default parameter.\n",
      "                open_api_key was transferred to model_kwargs.\n",
      "                Please confirm that open_api_key is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI  \n",
    "from decouple import config \n",
    "secrete_key = config('OPENAI_API_KEY')   \n",
    "\n",
    "chat= ChatOpenAI(open_api_key=secrete_key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI \n",
    "chat= OpenAI(openai_api_key=secrete_key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser  \n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser \n",
    "from langchain.output_parsers import PydanticOutputParser  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 1996-04-21T13:29:12.521362Z, 1036-08-08T11:04:50.665665Z, 0298-07-01T02:27:11.971113Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "date_time_parser =DatetimeOutputParser()  \n",
    "print(date_time_parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "cs_parser=CommaSeparatedListOutputParser() \n",
    "print(cs_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import  ChatOpenAI  \n",
    "from langchain.prompts import SystemMessagePromptTemplate , HumanMessagePromptTemplate , ChatPromptTemplate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formated_chat_prompts  is  [HumanMessage(content=\"what was the date when criecket world cup 2011 was declared \\nWrite a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1658-01-31T01:06:01.506126Z, 0246-01-25T14:24:27.415340Z, 0220-06-19T23:28:55.481326Z\\n\\nReturn ONLY this string, no other words!\")]\n"
     ]
    }
   ],
   "source": [
    "date_time_parser =DatetimeOutputParser()  \n",
    "human_template = \"{request}\\n{format_instructions}\"\n",
    "\n",
    "chat_prompt =ChatPromptTemplate.from_messages(\n",
    "    [HumanMessagePromptTemplate.from_template(human_template)\n",
    "     ])  \n",
    "\n",
    "\n",
    "formated_chat_prompts=chat_prompt.format_messages(\n",
    "    request=\"what was the date when criecket world cup 2011 was declared \" ,\n",
    "    format_instructions = date_time_parser.get_format_instructions()   \n",
    ")\n",
    " \n",
    "print(\"formated_chat_prompts  is \" , formated_chat_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response is  \n",
      "\n",
      "2011-04-02T00:00:00.000000Z\n"
     ]
    }
   ],
   "source": [
    "response=chat.invoke(formated_chat_prompts)  \n",
    "\n",
    "print(\"response is \" , response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 4, 2, 0, 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_time_parser.parse(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel , Field  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"name if footballer \", \"type\": \"string\"}, \"records\": {\"title\": \"Records\", \"description\": \"pyton list of records\", \"type\": \"array\", \"items\": {}}}, \"required\": [\"name\", \"records\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# example  3 \n",
    "\n",
    "class footballer(BaseModel ) :\n",
    "    name:str = Field(description=\"name if footballer \") \n",
    "    records:list = Field(description=\"pyton list of records\")   \n",
    "    \n",
    "    \n",
    "parser=PydanticOutputParser(pydantic_object=footballer) \n",
    "print(parser.get_format_instructions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define the Pydantic model for the parser\n",
    "class Footballer(BaseModel):\n",
    "    name: str = Field(description=\"name of the footballer\")\n",
    "    records: list = Field(description=\"list of records\")\n",
    "\n",
    "# Initialize the PydanticOutputParser with the model\n",
    "parser = PydanticOutputParser(pydantic_object=Footballer)\n",
    "\n",
    "# Define the human message template\n",
    "human_template = \"{request}\\n{format_instruction}\"\n",
    "\n",
    "# Create the chat prompt template\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(human_template)\n",
    "])\n",
    "\n",
    "# Generate the formatted chat prompt\n",
    "formatted_chat_prompts = chat_prompt.format_messages(\n",
    "    request=\"tell me about footballer\",\n",
    "    format_instruction=parser.get_format_instructions()  # Corrected key name\n",
    ")\n",
    "\n",
    "# print(formatted_chat_prompts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response is  name='Footballer' records=[{'title': 'Most goals scored in a season', 'description': 'The record for the most goals scored by a footballer in a single season.'}, {'title': 'Most appearances for a club', 'description': 'The record for the most appearances made by a footballer for a single club.'}, {'title': 'Most international caps', 'description': 'The record for the most appearances made by a footballer for their national team.'}]\n"
     ]
    }
   ],
   "source": [
    "response =chat.invoke(formatted_chat_prompts)  \n",
    "\n",
    "# print(\"response is \" , response)\n",
    "print(\"response is \" , \n",
    "      parser.parse(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import RegexParser\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "# Define the output parser\n",
    "parser = RegexParser(r\"The answer is: (.*)\")\n",
    "\n",
    "# Send a query to the language model\n",
    "prompt = \"What is the capital of France?\"\n",
    "response = llm(prompt)\n",
    "\n",
    "# Parse the response using the output parser\n",
    "parsed_response = parser.parse(response)\n",
    "\n",
    "# Access the extracted information\n",
    "answer = parsed_response[\"result\"][0]\n",
    "print(f\"The capital of France is {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import NLPOutputParser\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "# Define the output parser\n",
    "parser = NLPOutputParser()\n",
    "\n",
    "# Send a query to the language model\n",
    "prompt = \"Who are the main characters in the Harry Potter series?\"\n",
    "response = llm(prompt)\n",
    "\n",
    "# Parse the response using the output parser\n",
    "parsed_response = parser.parse(response)\n",
    "\n",
    "# Access the extracted information\n",
    "characters = parsed_response[\"names\"]\n",
    "print(f\"The main characters in the Harry Potter series are: {', '.join(characters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StringParser\n",
    "\n",
    "parser = StringParser(value=\"The answer is:\")\n",
    "\n",
    "response = \"The question was 'What is the capital of France?'. The answer is: Paris.\"\n",
    "parsed_response = parser.parse(response)\n",
    "print(parsed_response)  # Output: \"Paris.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "parser = StructuredOutputParser(\n",
    "    output_format=\"\"\"\n",
    "    The capital of {country} is {capital}.\n",
    "    The population of {capital} is {population} million.\n",
    "    \"\"\",\n",
    "    output_keys=[\"country\", \"capital\", \"population\"],\n",
    ")\n",
    "\n",
    "response = \"The capital of France is Paris. The population of Paris is 2.1 million.\"\n",
    "parsed_response = parser.parse(response)\n",
    "print(parsed_response)  # Output: {'country': 'France', 'capital': 'Paris', 'population': '2.1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import JSONOutputParser\n",
    "\n",
    "parser = JSONOutputParser()\n",
    "\n",
    "response = '{\"name\": \"John Doe\", \"age\": 32, \"city\": \"New York\"}'\n",
    "parsed_response = parser.parse(response)\n",
    "print(parsed_response)  # Output: {'name': 'John Doe', 'age': 32, 'city': 'New York'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CodeOutputParser\n",
    "\n",
    "parser = CodeOutputParser()\n",
    "\n",
    "response = \"Here's a Python function to reverse a string:\\n\\ndef reverse_string(s):\\n    return s[::-1]\"\n",
    "parsed_response = parser.parse(response)\n",
    "print(parsed_response)  # Output: \"def reverse_string(s):\\n    return s[::-1]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex Parser: Use regular expressions for structured text extraction.\n",
    "\n",
    "JSON Parser: Directly parse JSON responses.\n",
    "\n",
    "Custom Parser: Implement your own logic for specific parsing needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import RegexParser\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = OpenAI(api_key='your-openai-api-key')\n",
    "\n",
    "# Define a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"date\", \"event\"],\n",
    "    template=\"On {date}, the following event occurred: {event}.\"\n",
    ")\n",
    "\n",
    "# Define the regex parser\n",
    "pattern = r\"On (\\d{4}-\\d{2}-\\d{2}), the following event occurred: (.+)\"\n",
    "regex_parser = RegexParser(pattern=pattern, group_names=[\"date\", \"event\"])\n",
    "\n",
    "# Generate a response\n",
    "input_data = {\"date\": \"2023-05-21\", \"event\": \"The new AI model was released.\"}\n",
    "response = llm(prompt.format(**input_data))\n",
    "\n",
    "# Parse the response\n",
    "parsed_output = regex_parser.parse(response)\n",
    "print(parsed_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI \n",
    "chat= OpenAI(openai_api_key=secrete_key) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'New York Times', 'headline': 'Artificial Intelligence Continues to Advance and Transform Industries', 'date': 'June 23, 2021', 'category': 'Technology', 'author': 'John Smith', 'summary': \"The field of artificial intelligence (AI) continues to make major advancements, changing the way industries operate and transforming the world. From self-driving cars to virtual assistants, AI is becoming more integrated into our daily lives. In healthcare, AI is being used to improve patient diagnosis and treatment, while in finance, it is helping to detect fraud and make investment decisions. AI is also being used in agriculture to increase crop yields and in manufacturing to improve efficiency. However, concerns about AI's impact on jobs and its potential for bias and discrimination remain. Despite these challenges, the use of AI is expected to continue to grow and play a crucial role in shaping our future.\", 'link': 'https://www.nytimes.com/2021/06/23/technology/artificial-intelligence-ai-industries.html', 'image': 'https://static01.nyt.com/images/2021/06/23/business/23ai/23ai-superJumbo.jpg?quality'}\n"
     ]
    }
   ],
   "source": [
    "# jasonparser \n",
    "\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "# llm = OpenAI(api_key='your-openai-api-key')\n",
    "\n",
    "# Define a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Provide a summary of the latest news on {topic} in JSON format.\"\n",
    ")\n",
    "\n",
    "# Define the JSON parser\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "# Generate a response\n",
    "input_data = {\"topic\": \"artificial intelligence\"}\n",
    "response = chat(prompt.format(**input_data))\n",
    "\n",
    "# Parse the response\n",
    "parsed_output = json_parser.parse(response)\n",
    "print(parsed_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OutputParser' from 'langchain.output_parsers' (c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain\\output_parsers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# custom parser \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# from langchain.llms import OpenAI\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutputParser\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Custom parser class\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMyCustomParser\u001b[39;00m(OutputParser):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OutputParser' from 'langchain.output_parsers' (c:\\Users\\Jayraj\\anaconda3\\Lib\\site-packages\\langchain\\output_parsers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# custom parser \n",
    "\n",
    "# from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import OutputParser\n",
    "\n",
    "# Custom parser class\n",
    "class MyCustomParser(OutputParser):\n",
    "    def parse(self, text):\n",
    "        # Custom parsing logic here\n",
    "        lines = text.split(\"\\n\")\n",
    "        parsed_data = {\n",
    "            \"title\": lines[0],\n",
    "            \"description\": \" \".join(lines[1:])\n",
    "        }\n",
    "        return parsed_data\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = OpenAI(api_key='your-openai-api-key')\n",
    "\n",
    "# Define a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"Provide a detailed explanation on the topic in 2 line: {query}\"\n",
    ")\n",
    "\n",
    "# Use the custom parser\n",
    "custom_parser = MyCustomParser()\n",
    "\n",
    "# Generate a response\n",
    "input_data = {\"query\": \"quantum computing\"}\n",
    "response = chat(prompt.format(**input_data))\n",
    "\n",
    "# Parse the response\n",
    "parsed_output = custom_parser.parse(response)\n",
    "print(parsed_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Parser: Parses a list of items from the response.\n",
    "\n",
    "Table Parser: Converts tabular data into structured formats.\n",
    "\n",
    "Keyword Extraction Parser: Extracts specific keywords or phrases.\n",
    "\n",
    "JSON Path Parser: Extracts specific data points from nested JSON responses.\n",
    "\n",
    "Sentiment Analysis Parser: Analyzes and categorizes the sentiment of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ListParser\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = OpenAI(api_key='your-openai-api-key')\n",
    "\n",
    "# Define a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"List the main points about {topic}:\"\n",
    ")\n",
    "\n",
    "# Define the list parser\n",
    "list_parser = ListParser(item_separator='\\n')\n",
    "\n",
    "# Generate a response\n",
    "input_data = {\"topic\": \"benefits of meditation\"}\n",
    "response = llm(prompt.format(**input_data))\n",
    "\n",
    "# Parse the response\n",
    "parsed_output = list_parser.parse(response)\n",
    "print(parsed_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import ListParser\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = OpenAI(api_key='your-openai-api-key')\n",
    "\n",
    "# Define a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"List the main points about {topic}:\"\n",
    ")\n",
    "\n",
    "# Define the list parser\n",
    "list_parser = ListParser(item_separator='\\n')\n",
    "\n",
    "# Generate a response\n",
    "input_data = {\"topic\": \"benefits of meditation\"}\n",
    "response = llm(prompt.format(**input_data))\n",
    "\n",
    "# Parse the response\n",
    "parsed_output = list_parser.parse(response)\n",
    "print(parsed_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import KeywordExtractionParser\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = OpenAI(api_key='your-openai-api-key')\n",
    "\n",
    "# Define a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\"Extract the main keywords from the following text: {text}\"\n",
    ")\n",
    "\n",
    "# Define the keyword extraction parser\n",
    "keywords_to_extract = [\"AI\", \"machine learning\", \"deep learning\"]\n",
    "keyword_parser = KeywordExtractionParser(keywords=keywords_to_extract)\n",
    "\n",
    "# Generate a response\n",
    "input_data = {\"text\": \"Artificial Intelligence and Machine Learning are subsets of deep learning technologies.\"}\n",
    "response = llm(prompt.format(**input_data))\n",
    "\n",
    "# Parse the response\n",
    "parsed_output = keyword_parser.parse(response)\n",
    "print(parsed_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import JsonPathParser\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = OpenAI(api_key='your-openai-api-key')\n",
    "\n",
    "# Define a prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Provide a detailed report about {topic} in JSON format.\"\n",
    ")\n",
    "\n",
    "# Define the JSON Path parser\n",
    "json_path_expressions = {\"summary\": \"$.report.summary\", \"details\": \"$.report.details\"}\n",
    "json_path_parser = JsonPathParser(json_paths=json_path_expressions)\n",
    "\n",
    "# Generate a response\n",
    "input_data = {\"topic\": \"climate change\"}\n",
    "response = llm(prompt.format(**input_data))\n",
    "\n",
    "# Parse the response\n",
    "parsed_output = json_path_parser.parse(response)\n",
    "print(parsed_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
